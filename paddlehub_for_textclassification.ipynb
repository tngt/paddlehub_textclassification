{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.查看Paddle、PaddleHub版本及模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----打印paddle的版本信息:-----\n",
      "2.0.2\n",
      "-----打印paddlehub的版本信息:-----\n",
      "2.0.4\n",
      "-----打印ernie模型信息:-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-18 16:24:30,445] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ernie(\n",
      "  (model): ErnieModel(\n",
      "    (embeddings): ErnieEmbeddings(\n",
      "      (word_embeddings): Embedding(18000, 768, padding_idx=0, sparse=False)\n",
      "      (position_embeddings): Embedding(513, 768, sparse=False)\n",
      "      (token_type_embeddings): Embedding(2, 768, sparse=False)\n",
      "      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "    )\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): LayerList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): ErniePooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlehub as h\n",
    "from paddlehub.datasets.base_nlp_dataset import TextClassificationDataset\n",
    "\n",
    "# 打印paddle的版本信息\n",
    "print('-----打印paddle的版本信息:-----')\n",
    "print(paddle.__version__)\n",
    "\n",
    "# 打印paddlehub的版本信息\n",
    "print('-----打印paddlehub的版本信息:-----')\n",
    "print(h.__version__)\n",
    "\n",
    "# 打印ernie模型信息\n",
    "print('-----打印ernie模型信息:-----')\n",
    "print(h.Module(name='ernie'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.打印THUCNews验证集前3条、后3条数据  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! tar --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 解压数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thu_news/\r\n",
      "thu_news/test.txt\r\n",
      "thu_news/valid.txt\r\n",
      "thu_news/train.txt\r\n"
     ]
    }
   ],
   "source": [
    "! tar -xvf data/data80226/thu_news.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2打印验证集前三条数据、后三条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_a\tlabel\n",
      "直击特里勾手助小牛反超神鸟发威火箭仍处劣势　　新浪体育讯　北京时间4月16日消息，火箭今天迎来常规赛的收官战。客场挑战达拉斯小牛的比赛将关系到火箭队最终的排名，目前西部的竞争仍然非常激励。尤其是西部第二到第七的六支球队将在今天展开捉对厮杀的情况下，黄蜂、小牛、开拓者以及马刺都有可能是火箭队的下一个对手。以下为本场比赛的精彩瞬间——　　第四节比赛还剩下8分多钟，姚明重新回到场上，但是小牛队的霍里随后在右翼接队友传球后上演一记三分跳投，虽然身体动作已经变形，但是他仍然将球命中，随后基德在弧顶处的一记三分跳投帮助小牛终于将比分反超，火箭在进攻中直接打不开局面，而小牛更是利用特里空切后的一记勾手将比分反超至4分，包括库班在内的所有小牛现场球迷都站起来振臂高呼，而此时阿德尔曼还在场边低头深沉的思索中。　　比赛还剩下最后5分多钟，洛瑞带球突破中被小牛队员犯规，洛瑞来不及刹车让自己直接撞到了观众席上，右腿疼痛难忍的他脸都几乎变形，结果他两罚两中，火箭队还落后两分。随后，洛瑞将球直接传给此时已经回到场上的阿泰，野兽此时将球稳下，并没有急于进攻，随后他顺势将球塞给兰德里，神鸟利用对方站位空隙直接杀到篮下，上篮成功，火箭将比分终于追至80平。场上局面对于火箭来说绝对是不容有失。　　(sabrina)\t体育\n",
      "北京网购年消费额112亿元　　商报讯(记者吴文治)昨日，淘宝网发布的《2009-2010年度中国网购热门城市报告》显示，北京年度网购消费力达112.5亿元，与上海相差近62亿元，位列十大热门消费力城市第二位。此外，男性网购的消费金额高出女性，与“女性是网购主力军”的传统观念不符。　　淘宝公布的报告显示，中国网购消费力十大城市分别是上海、北京、深圳、杭州、广州、南京、苏州、天津、温州和宁波。主要集中在以江浙沪为主的长三角地区、以广深为主的珠三角地区和以北京为主的京津地区。北京年度网购112.5亿元的消费额，占国内城市网购消费额的5.6%。　　中国网购消费力十大城市的消费金额性别来源比例中，男性占比超过了女性。前者占比达到53.5%，后者则为46.5%。不过，在成交人数、成交笔数等关键数据上显示，女性消费者均高于男性。此外，在十大网购热门城市中，25岁-34岁的群体成为网购消费的主力军，占比达到62.49%。\t科技\n",
      "事业测试：你工作易受他人干扰吗(图)　　独家撰稿：苑椿　心理测试征稿启事 欢迎关注新浪星座微博　　办公室永远是个龙蛇混杂、藏龙卧虎的地方，你永远不知道一张张面具底下会是怎样的脸庞，你是否还傻傻的对别人的话听之任之，完全搞乱了自己工作的步调？还是笃定的坚守阵地，从未被谣言动摇分毫？赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\n",
      "趣味测试：你怎么红红火火过春节(图)　　独家撰稿：岚　心理测试征稿启事 欢迎关注新浪星座微博　　红红火火过大年啦，每年的此时你都会如何度过呢？是跟家人爱人在一起还是跟朋友兄弟外出欢聚呢？亦或背起行囊远离嘈杂，无论如何，总会有一种适合你的方式，赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\n",
      "人际测试：你的人际磁场强大吗(图)　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。\t星座\n"
     ]
    }
   ],
   "source": [
    "# 前三条数据\n",
    "!head -n 3 thu_news/valid.txt\n",
    "# 后三条数据\n",
    "!tail -n 3 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.基于PaddleHub的新闻文本分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "利用PaddleHub的预训练模型ernie完成新闻分类的迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ThuNews(TextClassificationDataset):\n",
    "    #数据集的标签列表\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_len=128,mode='train'):\n",
    "        if mode == 'train':\n",
    "            data_file = 'train.txt'\n",
    "        elif mode == 'test':\n",
    "            data_file = 'test.txt'\n",
    "        else:\n",
    "            data_file = 'valid.txt'\n",
    "\n",
    "        super(ThuNews, self).__init__(\n",
    "            base_path='thu_news',\n",
    "            data_file=data_file,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=max_seq_len,\n",
    "            mode=mode,\n",
    "            is_file_with_header=True,\n",
    "            label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-18 15:57:57,504] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "[2021-04-18 15:57:59,227] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# 模型加载\n",
    "model = h.Module(name='ernie', task='seq-cls', num_classes=14)\n",
    "tokenizer = model.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 实例化数据集\n",
    "train_dataset = ThuNews(tokenizer, mode='train')\n",
    "dev_dataset = ThuNews(tokenizer, mode='dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 加载数据、模型训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-18 16:00:03,928] [ WARNING] - PaddleHub model checkpoint not found, start from scratch...\n",
      "[2021-04-18 16:00:06,249] [   TRAIN] - Epoch=1/5, Step=10/282 loss=2.2596 acc=0.2938 lr=0.000050 step/sec=4.33 | ETA 00:05:25\n",
      "[2021-04-18 16:00:08,360] [   TRAIN] - Epoch=1/5, Step=20/282 loss=1.4753 acc=0.6344 lr=0.000050 step/sec=4.74 | ETA 00:05:11\n",
      "[2021-04-18 16:00:10,473] [   TRAIN] - Epoch=1/5, Step=30/282 loss=1.0994 acc=0.7188 lr=0.000050 step/sec=4.73 | ETA 00:05:07\n",
      "[2021-04-18 16:00:12,580] [   TRAIN] - Epoch=1/5, Step=40/282 loss=0.7771 acc=0.8187 lr=0.000050 step/sec=4.75 | ETA 00:05:04\n",
      "[2021-04-18 16:00:14,691] [   TRAIN] - Epoch=1/5, Step=50/282 loss=0.6346 acc=0.8594 lr=0.000050 step/sec=4.74 | ETA 00:05:03\n",
      "[2021-04-18 16:00:16,829] [   TRAIN] - Epoch=1/5, Step=60/282 loss=0.6976 acc=0.8187 lr=0.000050 step/sec=4.68 | ETA 00:05:02\n",
      "[2021-04-18 16:00:18,967] [   TRAIN] - Epoch=1/5, Step=70/282 loss=0.5340 acc=0.8812 lr=0.000050 step/sec=4.68 | ETA 00:05:02\n",
      "[2021-04-18 16:00:21,107] [   TRAIN] - Epoch=1/5, Step=80/282 loss=0.5007 acc=0.8719 lr=0.000050 step/sec=4.67 | ETA 00:05:02\n",
      "[2021-04-18 16:00:23,248] [   TRAIN] - Epoch=1/5, Step=90/282 loss=0.3261 acc=0.9281 lr=0.000050 step/sec=4.67 | ETA 00:05:02\n",
      "[2021-04-18 16:00:25,389] [   TRAIN] - Epoch=1/5, Step=100/282 loss=0.3607 acc=0.9125 lr=0.000050 step/sec=4.67 | ETA 00:05:02\n",
      "[2021-04-18 16:00:27,539] [   TRAIN] - Epoch=1/5, Step=110/282 loss=0.2947 acc=0.9281 lr=0.000050 step/sec=4.65 | ETA 00:05:02\n",
      "[2021-04-18 16:00:29,682] [   TRAIN] - Epoch=1/5, Step=120/282 loss=0.3419 acc=0.9125 lr=0.000050 step/sec=4.67 | ETA 00:05:02\n",
      "[2021-04-18 16:00:31,823] [   TRAIN] - Epoch=1/5, Step=130/282 loss=0.3133 acc=0.9094 lr=0.000050 step/sec=4.67 | ETA 00:05:02\n",
      "[2021-04-18 16:00:33,956] [   TRAIN] - Epoch=1/5, Step=140/282 loss=0.2003 acc=0.9563 lr=0.000050 step/sec=4.69 | ETA 00:05:02\n",
      "[2021-04-18 16:00:36,098] [   TRAIN] - Epoch=1/5, Step=150/282 loss=0.2805 acc=0.9313 lr=0.000050 step/sec=4.67 | ETA 00:05:02\n",
      "[2021-04-18 16:00:38,221] [   TRAIN] - Epoch=1/5, Step=160/282 loss=0.3431 acc=0.9156 lr=0.000050 step/sec=4.71 | ETA 00:05:02\n",
      "[2021-04-18 16:00:40,350] [   TRAIN] - Epoch=1/5, Step=170/282 loss=0.3427 acc=0.9000 lr=0.000050 step/sec=4.70 | ETA 00:05:01\n",
      "[2021-04-18 16:00:42,470] [   TRAIN] - Epoch=1/5, Step=180/282 loss=0.2627 acc=0.9344 lr=0.000050 step/sec=4.72 | ETA 00:05:01\n",
      "[2021-04-18 16:00:44,596] [   TRAIN] - Epoch=1/5, Step=190/282 loss=0.3627 acc=0.9031 lr=0.000050 step/sec=4.71 | ETA 00:05:01\n",
      "[2021-04-18 16:00:46,713] [   TRAIN] - Epoch=1/5, Step=200/282 loss=0.2477 acc=0.9531 lr=0.000050 step/sec=4.72 | ETA 00:05:01\n",
      "[2021-04-18 16:00:48,857] [   TRAIN] - Epoch=1/5, Step=210/282 loss=0.3274 acc=0.9094 lr=0.000050 step/sec=4.66 | ETA 00:05:01\n",
      "[2021-04-18 16:00:51,014] [   TRAIN] - Epoch=1/5, Step=220/282 loss=0.2923 acc=0.9125 lr=0.000050 step/sec=4.64 | ETA 00:05:01\n",
      "[2021-04-18 16:00:53,183] [   TRAIN] - Epoch=1/5, Step=230/282 loss=0.2726 acc=0.9344 lr=0.000050 step/sec=4.61 | ETA 00:05:01\n",
      "[2021-04-18 16:00:55,343] [   TRAIN] - Epoch=1/5, Step=240/282 loss=0.2612 acc=0.9281 lr=0.000050 step/sec=4.63 | ETA 00:05:01\n",
      "[2021-04-18 16:00:57,490] [   TRAIN] - Epoch=1/5, Step=250/282 loss=0.3205 acc=0.9062 lr=0.000050 step/sec=4.66 | ETA 00:05:02\n",
      "[2021-04-18 16:00:59,640] [   TRAIN] - Epoch=1/5, Step=260/282 loss=0.2670 acc=0.9344 lr=0.000050 step/sec=4.65 | ETA 00:05:02\n",
      "[2021-04-18 16:01:01,790] [   TRAIN] - Epoch=1/5, Step=270/282 loss=0.2599 acc=0.9250 lr=0.000050 step/sec=4.65 | ETA 00:05:02\n",
      "[2021-04-18 16:01:03,937] [   TRAIN] - Epoch=1/5, Step=280/282 loss=0.2710 acc=0.9250 lr=0.000050 step/sec=4.66 | ETA 00:05:02\n",
      "[2021-04-18 16:01:07,563] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.9000\n",
      "[2021-04-18 16:01:20,781] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.9000]\n",
      "[2021-04-18 16:01:20,784] [    INFO] - Saving model checkpoint to ckpt/epoch_1\n",
      "[2021-04-18 16:01:35,971] [   TRAIN] - Epoch=2/5, Step=10/282 loss=0.1794 acc=0.9531 lr=0.000050 step/sec=0.37 | ETA 00:07:24\n",
      "[2021-04-18 16:01:38,090] [   TRAIN] - Epoch=2/5, Step=20/282 loss=0.1448 acc=0.9625 lr=0.000050 step/sec=4.72 | ETA 00:07:19\n",
      "[2021-04-18 16:01:40,236] [   TRAIN] - Epoch=2/5, Step=30/282 loss=0.1978 acc=0.9437 lr=0.000050 step/sec=4.66 | ETA 00:07:15\n",
      "[2021-04-18 16:01:42,382] [   TRAIN] - Epoch=2/5, Step=40/282 loss=0.2026 acc=0.9469 lr=0.000050 step/sec=4.66 | ETA 00:07:11\n",
      "[2021-04-18 16:01:44,527] [   TRAIN] - Epoch=2/5, Step=50/282 loss=0.1608 acc=0.9531 lr=0.000050 step/sec=4.66 | ETA 00:07:07\n",
      "[2021-04-18 16:01:46,656] [   TRAIN] - Epoch=2/5, Step=60/282 loss=0.1675 acc=0.9625 lr=0.000050 step/sec=4.70 | ETA 00:07:03\n",
      "[2021-04-18 16:01:48,785] [   TRAIN] - Epoch=2/5, Step=70/282 loss=0.1532 acc=0.9594 lr=0.000050 step/sec=4.70 | ETA 00:06:59\n",
      "[2021-04-18 16:01:50,919] [   TRAIN] - Epoch=2/5, Step=80/282 loss=0.1691 acc=0.9375 lr=0.000050 step/sec=4.69 | ETA 00:06:56\n",
      "[2021-04-18 16:01:53,050] [   TRAIN] - Epoch=2/5, Step=90/282 loss=0.1621 acc=0.9656 lr=0.000050 step/sec=4.69 | ETA 00:06:53\n",
      "[2021-04-18 16:01:55,190] [   TRAIN] - Epoch=2/5, Step=100/282 loss=0.1414 acc=0.9625 lr=0.000050 step/sec=4.67 | ETA 00:06:50\n",
      "[2021-04-18 16:01:57,324] [   TRAIN] - Epoch=2/5, Step=110/282 loss=0.1531 acc=0.9563 lr=0.000050 step/sec=4.68 | ETA 00:06:47\n",
      "[2021-04-18 16:01:59,456] [   TRAIN] - Epoch=2/5, Step=120/282 loss=0.1570 acc=0.9625 lr=0.000050 step/sec=4.69 | ETA 00:06:45\n",
      "[2021-04-18 16:02:01,591] [   TRAIN] - Epoch=2/5, Step=130/282 loss=0.1271 acc=0.9656 lr=0.000050 step/sec=4.68 | ETA 00:06:42\n",
      "[2021-04-18 16:02:03,730] [   TRAIN] - Epoch=2/5, Step=140/282 loss=0.1441 acc=0.9563 lr=0.000050 step/sec=4.67 | ETA 00:06:40\n",
      "[2021-04-18 16:02:05,873] [   TRAIN] - Epoch=2/5, Step=150/282 loss=0.1710 acc=0.9594 lr=0.000050 step/sec=4.67 | ETA 00:06:37\n",
      "[2021-04-18 16:02:08,018] [   TRAIN] - Epoch=2/5, Step=160/282 loss=0.1667 acc=0.9437 lr=0.000050 step/sec=4.66 | ETA 00:06:35\n",
      "[2021-04-18 16:02:10,156] [   TRAIN] - Epoch=2/5, Step=170/282 loss=0.1547 acc=0.9531 lr=0.000050 step/sec=4.68 | ETA 00:06:33\n",
      "[2021-04-18 16:02:12,291] [   TRAIN] - Epoch=2/5, Step=180/282 loss=0.1820 acc=0.9563 lr=0.000050 step/sec=4.68 | ETA 00:06:31\n",
      "[2021-04-18 16:02:14,425] [   TRAIN] - Epoch=2/5, Step=190/282 loss=0.1381 acc=0.9688 lr=0.000050 step/sec=4.69 | ETA 00:06:29\n",
      "[2021-04-18 16:02:16,560] [   TRAIN] - Epoch=2/5, Step=200/282 loss=0.1757 acc=0.9500 lr=0.000050 step/sec=4.68 | ETA 00:06:27\n",
      "[2021-04-18 16:02:18,696] [   TRAIN] - Epoch=2/5, Step=210/282 loss=0.1362 acc=0.9625 lr=0.000050 step/sec=4.68 | ETA 00:06:26\n",
      "[2021-04-18 16:02:20,831] [   TRAIN] - Epoch=2/5, Step=220/282 loss=0.2092 acc=0.9437 lr=0.000050 step/sec=4.69 | ETA 00:06:24\n",
      "[2021-04-18 16:02:22,963] [   TRAIN] - Epoch=2/5, Step=230/282 loss=0.1454 acc=0.9625 lr=0.000050 step/sec=4.69 | ETA 00:06:22\n",
      "[2021-04-18 16:02:25,105] [   TRAIN] - Epoch=2/5, Step=240/282 loss=0.1569 acc=0.9594 lr=0.000050 step/sec=4.67 | ETA 00:06:21\n",
      "[2021-04-18 16:02:27,246] [   TRAIN] - Epoch=2/5, Step=250/282 loss=0.1408 acc=0.9594 lr=0.000050 step/sec=4.67 | ETA 00:06:19\n",
      "[2021-04-18 16:02:29,392] [   TRAIN] - Epoch=2/5, Step=260/282 loss=0.1579 acc=0.9563 lr=0.000050 step/sec=4.66 | ETA 00:06:18\n",
      "[2021-04-18 16:02:31,532] [   TRAIN] - Epoch=2/5, Step=270/282 loss=0.1673 acc=0.9500 lr=0.000050 step/sec=4.67 | ETA 00:06:17\n",
      "[2021-04-18 16:02:33,665] [   TRAIN] - Epoch=2/5, Step=280/282 loss=0.1771 acc=0.9500 lr=0.000050 step/sec=4.69 | ETA 00:06:15\n",
      "[2021-04-18 16:02:37,260] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.9086\n",
      "[2021-04-18 16:02:50,935] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.9086]\n",
      "[2021-04-18 16:02:50,938] [    INFO] - Saving model checkpoint to ckpt/epoch_2\n",
      "[2021-04-18 16:03:05,974] [   TRAIN] - Epoch=3/5, Step=10/282 loss=0.1104 acc=0.9719 lr=0.000050 step/sec=0.37 | ETA 00:07:27\n",
      "[2021-04-18 16:03:08,100] [   TRAIN] - Epoch=3/5, Step=20/282 loss=0.1150 acc=0.9750 lr=0.000050 step/sec=4.70 | ETA 00:07:24\n",
      "[2021-04-18 16:03:10,239] [   TRAIN] - Epoch=3/5, Step=30/282 loss=0.0635 acc=0.9875 lr=0.000050 step/sec=4.67 | ETA 00:07:22\n",
      "[2021-04-18 16:03:12,371] [   TRAIN] - Epoch=3/5, Step=40/282 loss=0.0698 acc=0.9906 lr=0.000050 step/sec=4.69 | ETA 00:07:19\n",
      "[2021-04-18 16:03:14,496] [   TRAIN] - Epoch=3/5, Step=50/282 loss=0.1132 acc=0.9625 lr=0.000050 step/sec=4.71 | ETA 00:07:17\n",
      "[2021-04-18 16:03:16,624] [   TRAIN] - Epoch=3/5, Step=60/282 loss=0.0540 acc=0.9812 lr=0.000050 step/sec=4.70 | ETA 00:07:15\n",
      "[2021-04-18 16:03:18,762] [   TRAIN] - Epoch=3/5, Step=70/282 loss=0.0714 acc=0.9812 lr=0.000050 step/sec=4.68 | ETA 00:07:13\n",
      "[2021-04-18 16:03:20,901] [   TRAIN] - Epoch=3/5, Step=80/282 loss=0.0918 acc=0.9719 lr=0.000050 step/sec=4.67 | ETA 00:07:11\n",
      "[2021-04-18 16:03:23,030] [   TRAIN] - Epoch=3/5, Step=90/282 loss=0.0763 acc=0.9750 lr=0.000050 step/sec=4.70 | ETA 00:07:09\n",
      "[2021-04-18 16:03:25,168] [   TRAIN] - Epoch=3/5, Step=100/282 loss=0.0531 acc=0.9906 lr=0.000050 step/sec=4.68 | ETA 00:07:07\n",
      "[2021-04-18 16:03:27,302] [   TRAIN] - Epoch=3/5, Step=110/282 loss=0.1170 acc=0.9688 lr=0.000050 step/sec=4.69 | ETA 00:07:05\n",
      "[2021-04-18 16:03:29,438] [   TRAIN] - Epoch=3/5, Step=120/282 loss=0.0615 acc=0.9844 lr=0.000050 step/sec=4.68 | ETA 00:07:03\n",
      "[2021-04-18 16:03:31,584] [   TRAIN] - Epoch=3/5, Step=130/282 loss=0.0870 acc=0.9719 lr=0.000050 step/sec=4.66 | ETA 00:07:01\n",
      "[2021-04-18 16:03:33,729] [   TRAIN] - Epoch=3/5, Step=140/282 loss=0.0756 acc=0.9812 lr=0.000050 step/sec=4.66 | ETA 00:07:00\n",
      "[2021-04-18 16:03:35,863] [   TRAIN] - Epoch=3/5, Step=150/282 loss=0.0567 acc=0.9812 lr=0.000050 step/sec=4.68 | ETA 00:06:58\n",
      "[2021-04-18 16:03:37,997] [   TRAIN] - Epoch=3/5, Step=160/282 loss=0.0796 acc=0.9719 lr=0.000050 step/sec=4.69 | ETA 00:06:56\n",
      "[2021-04-18 16:03:40,144] [   TRAIN] - Epoch=3/5, Step=170/282 loss=0.0711 acc=0.9781 lr=0.000050 step/sec=4.66 | ETA 00:06:55\n",
      "[2021-04-18 16:03:42,283] [   TRAIN] - Epoch=3/5, Step=180/282 loss=0.0885 acc=0.9719 lr=0.000050 step/sec=4.68 | ETA 00:06:53\n",
      "[2021-04-18 16:03:44,429] [   TRAIN] - Epoch=3/5, Step=190/282 loss=0.1005 acc=0.9656 lr=0.000050 step/sec=4.66 | ETA 00:06:52\n",
      "[2021-04-18 16:03:46,572] [   TRAIN] - Epoch=3/5, Step=200/282 loss=0.0708 acc=0.9844 lr=0.000050 step/sec=4.67 | ETA 00:06:50\n",
      "[2021-04-18 16:03:48,704] [   TRAIN] - Epoch=3/5, Step=210/282 loss=0.0709 acc=0.9781 lr=0.000050 step/sec=4.69 | ETA 00:06:49\n",
      "[2021-04-18 16:03:50,858] [   TRAIN] - Epoch=3/5, Step=220/282 loss=0.1037 acc=0.9750 lr=0.000050 step/sec=4.64 | ETA 00:06:48\n",
      "[2021-04-18 16:03:53,010] [   TRAIN] - Epoch=3/5, Step=230/282 loss=0.1041 acc=0.9719 lr=0.000050 step/sec=4.65 | ETA 00:06:46\n",
      "[2021-04-18 16:03:55,163] [   TRAIN] - Epoch=3/5, Step=240/282 loss=0.0867 acc=0.9750 lr=0.000050 step/sec=4.64 | ETA 00:06:45\n",
      "[2021-04-18 16:03:57,321] [   TRAIN] - Epoch=3/5, Step=250/282 loss=0.0616 acc=0.9844 lr=0.000050 step/sec=4.63 | ETA 00:06:44\n",
      "[2021-04-18 16:03:59,477] [   TRAIN] - Epoch=3/5, Step=260/282 loss=0.0538 acc=0.9875 lr=0.000050 step/sec=4.64 | ETA 00:06:43\n",
      "[2021-04-18 16:04:01,625] [   TRAIN] - Epoch=3/5, Step=270/282 loss=0.1307 acc=0.9594 lr=0.000050 step/sec=4.65 | ETA 00:06:41\n",
      "[2021-04-18 16:04:03,777] [   TRAIN] - Epoch=3/5, Step=280/282 loss=0.1122 acc=0.9719 lr=0.000050 step/sec=4.65 | ETA 00:06:40\n",
      "[2021-04-18 16:04:07,405] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.9107\n",
      "[2021-04-18 16:04:21,108] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.9107]\n",
      "[2021-04-18 16:04:21,111] [    INFO] - Saving model checkpoint to ckpt/epoch_3\n",
      "[2021-04-18 16:04:36,001] [   TRAIN] - Epoch=4/5, Step=10/282 loss=0.0634 acc=0.9812 lr=0.000050 step/sec=0.37 | ETA 00:07:28\n",
      "[2021-04-18 16:04:38,124] [   TRAIN] - Epoch=4/5, Step=20/282 loss=0.0545 acc=0.9875 lr=0.000050 step/sec=4.71 | ETA 00:07:26\n",
      "[2021-04-18 16:04:40,243] [   TRAIN] - Epoch=4/5, Step=30/282 loss=0.0410 acc=0.9906 lr=0.000050 step/sec=4.72 | ETA 00:07:24\n",
      "[2021-04-18 16:04:42,372] [   TRAIN] - Epoch=4/5, Step=40/282 loss=0.0252 acc=0.9938 lr=0.000050 step/sec=4.70 | ETA 00:07:23\n",
      "[2021-04-18 16:04:44,503] [   TRAIN] - Epoch=4/5, Step=50/282 loss=0.0257 acc=0.9938 lr=0.000050 step/sec=4.69 | ETA 00:07:21\n",
      "[2021-04-18 16:04:46,634] [   TRAIN] - Epoch=4/5, Step=60/282 loss=0.0177 acc=0.9969 lr=0.000050 step/sec=4.69 | ETA 00:07:19\n",
      "[2021-04-18 16:04:48,767] [   TRAIN] - Epoch=4/5, Step=70/282 loss=0.0825 acc=0.9812 lr=0.000050 step/sec=4.69 | ETA 00:07:18\n",
      "[2021-04-18 16:04:50,904] [   TRAIN] - Epoch=4/5, Step=80/282 loss=0.0506 acc=0.9875 lr=0.000050 step/sec=4.68 | ETA 00:07:16\n",
      "[2021-04-18 16:04:53,038] [   TRAIN] - Epoch=4/5, Step=90/282 loss=0.0395 acc=0.9844 lr=0.000050 step/sec=4.69 | ETA 00:07:15\n",
      "[2021-04-18 16:04:55,179] [   TRAIN] - Epoch=4/5, Step=100/282 loss=0.0297 acc=0.9969 lr=0.000050 step/sec=4.67 | ETA 00:07:14\n",
      "[2021-04-18 16:04:57,327] [   TRAIN] - Epoch=4/5, Step=110/282 loss=0.0486 acc=0.9812 lr=0.000050 step/sec=4.66 | ETA 00:07:12\n",
      "[2021-04-18 16:04:59,460] [   TRAIN] - Epoch=4/5, Step=120/282 loss=0.0726 acc=0.9781 lr=0.000050 step/sec=4.69 | ETA 00:07:11\n",
      "[2021-04-18 16:05:01,601] [   TRAIN] - Epoch=4/5, Step=130/282 loss=0.0781 acc=0.9781 lr=0.000050 step/sec=4.67 | ETA 00:07:10\n",
      "[2021-04-18 16:05:03,747] [   TRAIN] - Epoch=4/5, Step=140/282 loss=0.0602 acc=0.9781 lr=0.000050 step/sec=4.66 | ETA 00:07:08\n",
      "[2021-04-18 16:05:05,876] [   TRAIN] - Epoch=4/5, Step=150/282 loss=0.0510 acc=0.9906 lr=0.000050 step/sec=4.70 | ETA 00:07:07\n",
      "[2021-04-18 16:05:08,016] [   TRAIN] - Epoch=4/5, Step=160/282 loss=0.0776 acc=0.9812 lr=0.000050 step/sec=4.67 | ETA 00:07:06\n",
      "[2021-04-18 16:05:10,162] [   TRAIN] - Epoch=4/5, Step=170/282 loss=0.1118 acc=0.9781 lr=0.000050 step/sec=4.66 | ETA 00:07:04\n",
      "[2021-04-18 16:05:12,298] [   TRAIN] - Epoch=4/5, Step=180/282 loss=0.0310 acc=0.9875 lr=0.000050 step/sec=4.68 | ETA 00:07:03\n",
      "[2021-04-18 16:05:14,437] [   TRAIN] - Epoch=4/5, Step=190/282 loss=0.0581 acc=0.9875 lr=0.000050 step/sec=4.67 | ETA 00:07:02\n",
      "[2021-04-18 16:05:16,568] [   TRAIN] - Epoch=4/5, Step=200/282 loss=0.0314 acc=0.9938 lr=0.000050 step/sec=4.69 | ETA 00:07:01\n",
      "[2021-04-18 16:05:18,707] [   TRAIN] - Epoch=4/5, Step=210/282 loss=0.1003 acc=0.9688 lr=0.000050 step/sec=4.67 | ETA 00:07:00\n",
      "[2021-04-18 16:05:20,844] [   TRAIN] - Epoch=4/5, Step=220/282 loss=0.0526 acc=0.9781 lr=0.000050 step/sec=4.68 | ETA 00:06:59\n",
      "[2021-04-18 16:05:22,981] [   TRAIN] - Epoch=4/5, Step=230/282 loss=0.0321 acc=0.9875 lr=0.000050 step/sec=4.68 | ETA 00:06:58\n",
      "[2021-04-18 16:05:25,125] [   TRAIN] - Epoch=4/5, Step=240/282 loss=0.0851 acc=0.9844 lr=0.000050 step/sec=4.67 | ETA 00:06:57\n",
      "[2021-04-18 16:05:27,267] [   TRAIN] - Epoch=4/5, Step=250/282 loss=0.0698 acc=0.9844 lr=0.000050 step/sec=4.67 | ETA 00:06:55\n",
      "[2021-04-18 16:05:29,417] [   TRAIN] - Epoch=4/5, Step=260/282 loss=0.0532 acc=0.9844 lr=0.000050 step/sec=4.65 | ETA 00:06:54\n",
      "[2021-04-18 16:05:31,557] [   TRAIN] - Epoch=4/5, Step=270/282 loss=0.1007 acc=0.9688 lr=0.000050 step/sec=4.67 | ETA 00:06:53\n",
      "[2021-04-18 16:05:33,698] [   TRAIN] - Epoch=4/5, Step=280/282 loss=0.0718 acc=0.9781 lr=0.000050 step/sec=4.67 | ETA 00:06:52\n",
      "[2021-04-18 16:05:37,287] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.9150\n",
      "[2021-04-18 16:05:50,916] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.9150]\n",
      "[2021-04-18 16:05:50,919] [    INFO] - Saving model checkpoint to ckpt/epoch_4\n",
      "[2021-04-18 16:06:05,759] [   TRAIN] - Epoch=5/5, Step=10/282 loss=0.0597 acc=0.9750 lr=0.000050 step/sec=0.37 | ETA 00:07:28\n",
      "[2021-04-18 16:06:07,892] [   TRAIN] - Epoch=5/5, Step=20/282 loss=0.0242 acc=0.9969 lr=0.000050 step/sec=4.69 | ETA 00:07:27\n",
      "[2021-04-18 16:06:10,020] [   TRAIN] - Epoch=5/5, Step=30/282 loss=0.0443 acc=0.9844 lr=0.000050 step/sec=4.70 | ETA 00:07:25\n",
      "[2021-04-18 16:06:12,153] [   TRAIN] - Epoch=5/5, Step=40/282 loss=0.0730 acc=0.9781 lr=0.000050 step/sec=4.69 | ETA 00:07:24\n",
      "[2021-04-18 16:06:14,285] [   TRAIN] - Epoch=5/5, Step=50/282 loss=0.0500 acc=0.9906 lr=0.000050 step/sec=4.69 | ETA 00:07:23\n",
      "[2021-04-18 16:06:16,411] [   TRAIN] - Epoch=5/5, Step=60/282 loss=0.0482 acc=0.9844 lr=0.000050 step/sec=4.70 | ETA 00:07:22\n",
      "[2021-04-18 16:06:18,537] [   TRAIN] - Epoch=5/5, Step=70/282 loss=0.0765 acc=0.9875 lr=0.000050 step/sec=4.70 | ETA 00:07:20\n",
      "[2021-04-18 16:06:20,672] [   TRAIN] - Epoch=5/5, Step=80/282 loss=0.0399 acc=0.9875 lr=0.000050 step/sec=4.68 | ETA 00:07:19\n",
      "[2021-04-18 16:06:22,815] [   TRAIN] - Epoch=5/5, Step=90/282 loss=0.0360 acc=0.9906 lr=0.000050 step/sec=4.67 | ETA 00:07:18\n",
      "[2021-04-18 16:06:24,956] [   TRAIN] - Epoch=5/5, Step=100/282 loss=0.0400 acc=0.9875 lr=0.000050 step/sec=4.67 | ETA 00:07:17\n",
      "[2021-04-18 16:06:27,092] [   TRAIN] - Epoch=5/5, Step=110/282 loss=0.0112 acc=1.0000 lr=0.000050 step/sec=4.68 | ETA 00:07:16\n",
      "[2021-04-18 16:06:29,233] [   TRAIN] - Epoch=5/5, Step=120/282 loss=0.0203 acc=0.9906 lr=0.000050 step/sec=4.67 | ETA 00:07:15\n",
      "[2021-04-18 16:06:31,376] [   TRAIN] - Epoch=5/5, Step=130/282 loss=0.0443 acc=0.9844 lr=0.000050 step/sec=4.67 | ETA 00:07:14\n",
      "[2021-04-18 16:06:33,521] [   TRAIN] - Epoch=5/5, Step=140/282 loss=0.0448 acc=0.9844 lr=0.000050 step/sec=4.66 | ETA 00:07:13\n",
      "[2021-04-18 16:06:35,653] [   TRAIN] - Epoch=5/5, Step=150/282 loss=0.0574 acc=0.9844 lr=0.000050 step/sec=4.69 | ETA 00:07:12\n",
      "[2021-04-18 16:06:37,787] [   TRAIN] - Epoch=5/5, Step=160/282 loss=0.0800 acc=0.9719 lr=0.000050 step/sec=4.69 | ETA 00:07:11\n",
      "[2021-04-18 16:06:39,933] [   TRAIN] - Epoch=5/5, Step=170/282 loss=0.0270 acc=0.9906 lr=0.000050 step/sec=4.66 | ETA 00:07:10\n",
      "[2021-04-18 16:06:42,067] [   TRAIN] - Epoch=5/5, Step=180/282 loss=0.0315 acc=0.9938 lr=0.000050 step/sec=4.69 | ETA 00:07:09\n",
      "[2021-04-18 16:06:44,208] [   TRAIN] - Epoch=5/5, Step=190/282 loss=0.0439 acc=0.9875 lr=0.000050 step/sec=4.67 | ETA 00:07:08\n",
      "[2021-04-18 16:06:46,337] [   TRAIN] - Epoch=5/5, Step=200/282 loss=0.0390 acc=0.9906 lr=0.000050 step/sec=4.70 | ETA 00:07:07\n",
      "[2021-04-18 16:06:48,492] [   TRAIN] - Epoch=5/5, Step=210/282 loss=0.0366 acc=0.9906 lr=0.000050 step/sec=4.64 | ETA 00:07:06\n",
      "[2021-04-18 16:06:50,628] [   TRAIN] - Epoch=5/5, Step=220/282 loss=0.0413 acc=0.9875 lr=0.000050 step/sec=4.68 | ETA 00:07:05\n",
      "[2021-04-18 16:06:52,761] [   TRAIN] - Epoch=5/5, Step=230/282 loss=0.0671 acc=0.9750 lr=0.000050 step/sec=4.69 | ETA 00:07:04\n",
      "[2021-04-18 16:06:54,908] [   TRAIN] - Epoch=5/5, Step=240/282 loss=0.0389 acc=0.9906 lr=0.000050 step/sec=4.66 | ETA 00:07:03\n",
      "[2021-04-18 16:06:57,041] [   TRAIN] - Epoch=5/5, Step=250/282 loss=0.0255 acc=0.9938 lr=0.000050 step/sec=4.69 | ETA 00:07:02\n",
      "[2021-04-18 16:06:59,180] [   TRAIN] - Epoch=5/5, Step=260/282 loss=0.0501 acc=0.9875 lr=0.000050 step/sec=4.67 | ETA 00:07:01\n",
      "[2021-04-18 16:07:01,321] [   TRAIN] - Epoch=5/5, Step=270/282 loss=0.0772 acc=0.9875 lr=0.000050 step/sec=4.67 | ETA 00:07:00\n",
      "[2021-04-18 16:07:03,453] [   TRAIN] - Epoch=5/5, Step=280/282 loss=0.0298 acc=0.9938 lr=0.000050 step/sec=4.69 | ETA 00:07:00\n",
      "[2021-04-18 16:07:07,064] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.9207\n",
      "[2021-04-18 16:07:20,695] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.9207]\n",
      "[2021-04-18 16:07:20,697] [    INFO] - Saving model checkpoint to ckpt/epoch_5\n"
     ]
    }
   ],
   "source": [
    "optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())\n",
    "trainer = h.Trainer(model, optimizer, checkpoint_dir='ckpt', use_gpu=True)\n",
    "trainer.train(train_dataset, epochs=5, batch_size=32, eval_dataset=dev_dataset, save_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.4 模型预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-18 16:09:27,412] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "[2021-04-18 16:09:32,603] [    INFO] - Loaded parameters from /home/aistudio/ckpt/epoch_5/model.pdparams\n",
      "[2021-04-18 16:09:32,741] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 二环小户型前门前总价140万全款98折(图)　　新浪房产讯(编辑晏阳)　前门前(论坛相册户型样板间地图搜索)2009年4月25日开盘，均价25800元/平方米。项目分三期开发，一期为高档住宅，进深仅9.7米，南北通透，容积率2.3，目前在售为1、2、3号楼，6层板楼2梯4户，户型面积为60平米-170平米，均价25800元/平米，总价140万/套起，2009年11月30日入住。一次性98折！　　前门前项目位于二环内前门商业街的东南角，向南步行300米就是举世闻名的天坛公园，向东500米即为繁华的新世界商圈，总建筑面积12.5万平方米，占地面积3.9万平米。项目由西向东分为ABC三个区，A区是商务公寓，B区为50—170?阳光纯板，南北通透。C区是一个三进式仿古四合院。B区住宅即将开盘。　　前门前地处二环核心，前观天安门，后揽天坛公园，三线地铁交汇，距地铁7号线大都市街站约500米。周边遍布老北京五大商圈、同仁、协和医院等众多生活便利。项目青花瓷电梯间立基与天安门、祈年殿一线。规划上，采用中式围合布局，与项目周边众多古建和谐生趣，每个组团都有各自的院落，同时通过挑空一层，使得每个组团有益连接，种植更多大树、水系。内部空间上，楼体坐南朝北，室内空间格局方正，户户朝阳。　　以上信息仅供参考，最终以开发商公布为准。　　点击查看更多楼盘开盘信息。 \t Lable: 房产\n"
     ]
    }
   ],
   "source": [
    "# 在测试数据集中随机挑选出一条数据，标签为【房产】\n",
    "data = [[\"二环小户型前门前总价140万全款98折(图)　　新浪房产讯(编辑晏阳)　前门前(论坛相册户型样板间地图搜索)2009年4月25日开盘，均价25800元/平方米。项目分三期开发，一期为高档住宅，进深仅9.7米，南北通透，容积率2.3，目前在售为1、2、3号楼，6层板楼2梯4户，户型面积为60平米-170平米，均价25800元/平米，总价140万/套起，2009年11月30日入住。一次性98折！　　前门前项目位于二环内前门商业街的东南角，向南步行300米就是举世闻名的天坛公园，向东500米即为繁华的新世界商圈，总建筑面积12.5万平方米，占地面积3.9万平米。项目由西向东分为ABC三个区，A区是商务公寓，B区为50—170?阳光纯板，南北通透。C区是一个三进式仿古四合院。B区住宅即将开盘。　　前门前地处二环核心，前观天安门，后揽天坛公园，三线地铁交汇，距地铁7号线大都市街站约500米。周边遍布老北京五大商圈、同仁、协和医院等众多生活便利。项目青花瓷电梯间立基与天安门、祈年殿一线。规划上，采用中式围合布局，与项目周边众多古建和谐生趣，每个组团都有各自的院落，同时通过挑空一层，使得每个组团有益连接，种植更多大树、水系。内部空间上，楼体坐南朝北，室内空间格局方正，户户朝阳。　　以上信息仅供参考，最终以开发商公布为准。　　点击查看更多楼盘开盘信息。\"]]\n",
    "\n",
    "label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\n",
    "label_map = { \n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "\n",
    "model = h.Module(name='ernie',task='seq-cls',load_checkpoint='ckpt/epoch_5/model.pdparams',label_map=label_map)\n",
    "results = model.predict(data, max_seq_len=128, batch_size=1, use_gpu=True)\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text[0], results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
